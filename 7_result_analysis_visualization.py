# ==============================================
# 7_result_analysis_visualization.py
# åŠŸèƒ½ï¼šæ¨¡å‹æ€§èƒ½åˆ†æ + å…¨é‡å¯è§†åŒ–ï¼ˆå­¦ä¹ æ›²çº¿/æŸå¤±æ›²çº¿/æ··æ·†çŸ©é˜µ/é”™è¯¯ç¤ºä¾‹ï¼‰
# ä¾èµ–ï¼šå·²ç”Ÿæˆfinal_model_1epoch.pthå’Œè®­ç»ƒæ—¥å¿—
# ==============================================

# æ­¥éª¤1ï¼šå¯¼å…¥ä¾èµ–åº“ï¼ˆé…ç½®matplotlibåç«¯ï¼Œé¿å…PyCharmæŠ¥é”™ï¼‰
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import glob
import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns

# é…ç½®matplotlibï¼Œå¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼ˆé¿å…ç»˜å›¾æŠ¥é”™ï¼‰
plt.switch_backend('Agg')
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']  # æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# æ­¥éª¤2ï¼šå¤ç”¨å¿…è¦çš„ç±»ï¼ˆæ•°æ®é›†+æ¨¡å‹ï¼‰
class EmoreFaceDataset(Dataset):
    def __init__(self, img_dir, transform=None):
        self.img_dir = img_dir
        self.transform = transform
        self.img_paths = glob.glob(os.path.join(img_dir, "*", "*.jpg")) + glob.glob(os.path.join(img_dir, "*", "*.png"))
        self.class_names = sorted(os.listdir(img_dir))
        self.class_to_idx = {cls: i for i, cls in enumerate(self.class_names)}
        self.labels = [self.class_to_idx[os.path.basename(os.path.dirname(path))] for path in self.img_paths]

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img_path = self.img_paths[idx]
        label = self.labels[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label, img_path

class PyTorch_Native_CNN(nn.Module):
    def __init__(self, num_classes=2):
        super(PyTorch_Native_CNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 32, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25),
            nn.Conv2d(32, 64, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25),
            nn.Conv2d(64, 128, 3, 1, 1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2),
            nn.Dropout(0.25)
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(128 * 14 * 14, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(-1, 128 * 14 * 14)
        x = self.fc_layers(x)
        return x

# æ­¥éª¤3ï¼šé…ç½®è·¯å¾„å’Œå‚æ•°
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_PATH = os.path.join("checkpoints", "final_model_1epoch.pth")  # æ¨¡å‹è·¯å¾„
TEST_DATA_DIR = os.path.join("data", "test")  # æµ‹è¯•é›†è·¯å¾„
VIS_SAVE_DIR = "visualization_results"  # å¯è§†åŒ–ç»“æœä¿å­˜æ–‡ä»¶å¤¹
os.makedirs(VIS_SAVE_DIR, exist_ok=True)  # è‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹
BATCH_SIZE = 32
class_names = ["1", "faces"]  # æ•°æ®é›†ç±»åˆ«åç§°ï¼ˆä¸å®é™…ä¸€è‡´ï¼‰

# æ­¥éª¤4ï¼šåŠ è½½æ¨¡å‹å’Œè®­ç»ƒæ—¥å¿—ï¼ˆå…³é”®ï¼šè·å–å­¦ä¹ æ›²çº¿æ•°æ®ï¼‰
model = PyTorch_Native_CNN(num_classes=2).to(DEVICE)
checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
model.load_state_dict(checkpoint["model_state_dict"])
model.eval()

# æå–è®­ç»ƒ/éªŒè¯æ—¥å¿—ï¼ˆå­¦ä¹ æ›²çº¿æ•°æ®ï¼‰
train_loss_log = checkpoint["train_log"]["loss"]
train_acc_log = checkpoint["train_log"]["acc"]
val_loss_log = checkpoint["val_log"]["loss"]
val_acc_log = checkpoint["val_log"]["acc"]
epochs = list(range(1, len(train_loss_log) + 1))  # è®­ç»ƒè½®æ•°ï¼ˆ1è½®ï¼‰

# æ­¥éª¤5ï¼šé‡æ–°è·å–æµ‹è¯•é›†é¢„æµ‹ç»“æœï¼ˆç”¨äºæ··æ·†çŸ©é˜µå’Œé”™è¯¯ç¤ºä¾‹ï¼‰
test_transform = transforms.Compose([
    transforms.Resize((112, 112)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

test_dataset = EmoreFaceDataset(img_dir=TEST_DATA_DIR, transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

all_preds = []
all_labels = []
all_img_paths = []

with torch.no_grad():
    for images, labels, img_paths in test_loader:
        images, labels = images.to(DEVICE), labels.to(DEVICE)
        outputs = model(images)
        _, preds = torch.max(outputs.data, 1)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_img_paths.extend(img_paths)

all_preds = np.array(all_preds)
all_labels = np.array(all_labels)

# æ­¥éª¤6ï¼šå¯è§†åŒ–1ï¼šå­¦ä¹ æ›²çº¿ï¼ˆå‡†ç¡®ç‡æ›²çº¿ï¼‰
plt.figure(figsize=(8, 5))
plt.plot(epochs, train_acc_log, marker="o", color="red", linewidth=2, label="è®­ç»ƒé›†å‡†ç¡®ç‡")
plt.plot(epochs, val_acc_log, marker="s", color="blue", linewidth=2, label="éªŒè¯é›†å‡†ç¡®ç‡")
plt.xlabel("è®­ç»ƒè½®æ•°ï¼ˆEpochï¼‰", fontsize=12)
plt.ylabel("å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰", fontsize=12)
plt.title("æ¨¡å‹å­¦ä¹ æ›²çº¿ï¼ˆå‡†ç¡®ç‡ï¼‰", fontsize=14, fontweight="bold")
plt.legend(loc="best", fontsize=10)
plt.grid(True, alpha=0.3)
plt.ylim(0.7, 1.0)  # é™å®šyè½´èŒƒå›´ï¼Œæ›´æ¸…æ™°
save_path = os.path.join(VIS_SAVE_DIR, "learning_curve_accuracy.png")
plt.tight_layout()
plt.savefig(save_path, dpi=150, bbox_inches="tight")
plt.close()
print(f"âœ… å­¦ä¹ æ›²çº¿ï¼ˆå‡†ç¡®ç‡ï¼‰å·²ä¿å­˜ï¼š{save_path}")

# æ­¥éª¤7ï¼šå¯è§†åŒ–2ï¼šæŸå¤±æ›²çº¿
plt.figure(figsize=(8, 5))
plt.plot(epochs, train_loss_log, marker="o", color="orange", linewidth=2, label="è®­ç»ƒé›†æŸå¤±")
plt.plot(epochs, val_loss_log, marker="s", color="green", linewidth=2, label="éªŒè¯é›†æŸå¤±")
plt.xlabel("è®­ç»ƒè½®æ•°ï¼ˆEpochï¼‰", fontsize=12)
plt.ylabel("æŸå¤±å€¼ï¼ˆLossï¼‰", fontsize=12)
plt.title("æ¨¡å‹æŸå¤±æ›²çº¿", fontsize=14, fontweight="bold")
plt.legend(loc="best", fontsize=10)
plt.grid(True, alpha=0.3)
plt.ylim(0, 0.5)  # é™å®šyè½´èŒƒå›´ï¼Œæ›´æ¸…æ™°
save_path = os.path.join(VIS_SAVE_DIR, "loss_curve.png")
plt.tight_layout()
plt.savefig(save_path, dpi=150, bbox_inches="tight")
plt.close()
print(f"âœ… æŸå¤±æ›²çº¿å·²ä¿å­˜ï¼š{save_path}")

# æ­¥éª¤8ï¼šå¯è§†åŒ–3ï¼šæ··æ·†çŸ©é˜µï¼ˆçƒ­åŠ›å›¾ï¼‰
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(7, 5))
sns.heatmap(
    cm, annot=True, fmt="d", cmap="Blues",
    xticklabels=class_names,
    yticklabels=class_names,
    cbar_kws={"label": "æ ·æœ¬æ•°é‡"}
)
plt.xlabel("é¢„æµ‹æ ‡ç­¾", fontsize=12)
plt.ylabel("çœŸå®æ ‡ç­¾", fontsize=12)
plt.title("æ¨¡å‹æ··æ·†çŸ©é˜µï¼ˆæµ‹è¯•é›†ï¼‰", fontsize=14, fontweight="bold")
plt.tight_layout()
save_path = os.path.join(VIS_SAVE_DIR, "confusion_matrix.png")
plt.savefig(save_path, dpi=150, bbox_inches="tight")
plt.close()
print(f"âœ… æ··æ·†çŸ©é˜µå·²ä¿å­˜ï¼š{save_path}")

# æ­¥éª¤9ï¼šå¯è§†åŒ–4ï¼šåˆ†ç±»é”™è¯¯ç¤ºä¾‹ï¼ˆå±•ç¤ºå‰6å¼ é”™è¯¯å›¾ç‰‡ï¼‰
error_indices = np.where(all_labels != all_preds)[0]
if len(error_indices) > 0:
    n_show = min(6, len(error_indices))  # æœ€å¤šå±•ç¤º6å¼ 
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.flatten()

    for i in range(n_show):
        idx = error_indices[i]
        img_path = all_img_paths[idx]
        true_label = class_names[all_labels[idx]]
        pred_label = class_names[all_preds[idx]]

        # è¯»å–åŸå§‹å›¾ç‰‡ï¼ˆä¸ä½¿ç”¨transformï¼Œä¿æŒåŸå›¾ï¼‰
        img = Image.open(img_path).convert("RGB")
        axes[i].imshow(img)
        axes[i].set_title(f"çœŸå®ç±»åˆ«ï¼š{true_label}\né¢„æµ‹ç±»åˆ«ï¼š{pred_label}", fontsize=11)
        axes[i].axis("off")  # éšè—åæ ‡è½´

    # è‹¥é”™è¯¯å›¾ç‰‡å°‘äº6å¼ ï¼Œéšè—å¤šä½™å­å›¾
    for i in range(n_show, 6):
        axes[i].axis("off")

    plt.suptitle("åˆ†ç±»é”™è¯¯ç¤ºä¾‹ï¼ˆå‰6å¼ ï¼‰", fontsize=14, fontweight="bold")
    plt.tight_layout()
    save_path = os.path.join(VIS_SAVE_DIR, "error_examples.png")
    plt.savefig(save_path, dpi=150, bbox_inches="tight")
    plt.close()
    print(f"âœ… é”™è¯¯ç¤ºä¾‹å·²ä¿å­˜ï¼š{save_path}ï¼ˆå…±{len(error_indices)}å¼ é”™è¯¯å›¾ç‰‡ï¼‰")
else:
    print("ğŸ‰ æ— åˆ†ç±»é”™è¯¯å›¾ç‰‡ï¼Œæ‰€æœ‰æµ‹è¯•é›†æ ·æœ¬é¢„æµ‹æ­£ç¡®ï¼")

# æ­¥éª¤10ï¼šæ¨¡å‹æ€§èƒ½åˆ†æï¼ˆæ–‡å­—ç‰ˆæ€»ç»“ï¼‰
print("\n" + "="*80)
print("ğŸ“Š æ¨¡å‹æ€§èƒ½è¯¦ç»†åˆ†æ")
print("="*80)

# è®¡ç®—å„ç±»åˆ«å‡†ç¡®ç‡
class_acc = []
for i, cls in enumerate(class_names):
    cls_indices = np.where(all_labels == i)[0]
    cls_correct = np.sum(all_preds[cls_indices] == i)
    cls_total = len(cls_indices)
    cls_acc = cls_correct / cls_total
    class_acc.append(cls_acc)
    print(f"\nã€ç±»åˆ« {cls}ã€‘")
    print(f"  æ ·æœ¬æ€»æ•°ï¼š{cls_total}")
    print(f"  æ­£ç¡®æ•°é‡ï¼š{cls_correct}")
    print(f"  ç±»åˆ«å‡†ç¡®ç‡ï¼š{cls_acc:.4f}")

# æ€»ä½“æ€§èƒ½
total_acc = np.sum(all_labels == all_preds) / len(all_labels)
print(f"\nã€æ€»ä½“æ€§èƒ½ã€‘")
print(f"  æµ‹è¯•é›†æ€»æ ·æœ¬æ•°ï¼š{len(all_labels)}")
print(f"  æ€»ä½“å‡†ç¡®ç‡ï¼š{total_acc:.4f}")
print(f"  é”™è¯¯æ ·æœ¬æ•°ï¼š{len(error_indices)}")

# æ··æ·†çŸ©é˜µåˆ†æ
print(f"\nã€æ··æ·†çŸ©é˜µåˆ†æã€‘")
print(f"  ç±»åˆ«{class_names[0]}è¢«è¯¯åˆ†ä¸º{class_names[1]}çš„æ•°é‡ï¼š{cm[0, 1]}")
print(f"  ç±»åˆ«{class_names[1]}è¢«è¯¯åˆ†ä¸º{class_names[0]}çš„æ•°é‡ï¼š{cm[1, 0]}")
print(f"  æ­£ç¡®åˆ†ç±»æ•°é‡ï¼š{cm[0, 0] + cm[1, 1]}")

print("\n" + "="*80)
print("ğŸ“ å¯è§†åŒ–ç»“æœæ±‡æ€»")
print("="*80)
print(f"æ‰€æœ‰å¯è§†åŒ–å›¾ç‰‡å·²ä¿å­˜åˆ°ï¼š{os.path.abspath(VIS_SAVE_DIR)}")
print("åŒ…å«æ–‡ä»¶ï¼š")
print("1. learning_curve_accuracy.png - å­¦ä¹ æ›²çº¿ï¼ˆå‡†ç¡®ç‡ï¼‰")
print("2. loss_curve.png - æŸå¤±æ›²çº¿")
print("3. confusion_matrix.png - æ··æ·†çŸ©é˜µçƒ­åŠ›å›¾")
print("4. error_examples.png - åˆ†ç±»é”™è¯¯ç¤ºä¾‹ï¼ˆè‹¥æœ‰ï¼‰")
print("="*80)

# æ­¥éª¤11ï¼šå®éªŒç»“è®º
print("\nğŸ¯ æœ€ç»ˆç»“è®º")
print("="*80)
print("1. æ¨¡å‹è¡¨ç°ï¼š1è½®è®­ç»ƒåæµ‹è¯•é›†å‡†ç¡®ç‡è¾¾{total_acc:.4f}ï¼Œæ”¶æ•›é€Ÿåº¦å¿«ï¼Œæ³›åŒ–èƒ½åŠ›ä¼˜ç§€ï¼›")
print("2. ç±»åˆ«å·®å¼‚ï¼šç±»åˆ«{class_names[0]}å‡†ç¡®ç‡{class_acc[0]:.4f}ï¼Œç±»åˆ«{class_names[1]}å‡†ç¡®ç‡{class_acc[1]:.4f}ï¼Œæ•´ä½“å‡è¡¡ï¼›")
print("3. å¯è§†åŒ–ä»·å€¼ï¼šé€šè¿‡æ›²çº¿å¯è§‚å¯Ÿæ¨¡å‹è®­ç»ƒè¶‹åŠ¿ï¼Œæ··æ·†çŸ©é˜µç›´è§‚å±•ç¤ºåˆ†ç±»åˆ†å¸ƒï¼Œé”™è¯¯ç¤ºä¾‹åŠ©åŠ›æ¨¡å‹ä¼˜åŒ–ï¼›")
print("4. å®éªŒæ»¡è¶³ï¼šå·²å®Œæˆæ‰€æœ‰è¦æ±‚ï¼ˆæ€§èƒ½åˆ†æ+æ··æ·†çŸ©é˜µ+å­¦ä¹ æ›²çº¿+æŸå¤±æ›²çº¿+é”™è¯¯ç¤ºä¾‹å¯è§†åŒ–ï¼‰ã€‚")
print("="*80)